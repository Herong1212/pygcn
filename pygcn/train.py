from __future__ import division
from __future__ import print_function

import time
import argparse
import numpy as np

import torch
import torch.nn.functional as F
import torch.optim as optim
import pytz

print("pytz version:", pytz.__version__)

from datetime import datetime
from pygcn.utils import load_data, accuracy
from pygcn.models import GCN

# step1ï¼šTraining settings
parser = argparse.ArgumentParser()  # è®¾ç½®è¶…å‚æ•°ï¼Œå¦‚æ˜¯å¦ä½¿ç”¨ CUDAã€å­¦ä¹ ç‡ã€è®­ç»ƒè½®æ•°ç­‰
# è®¾ç½®æ˜¯å¦ç¦ç”¨ CUDA
parser.add_argument(
    "--cuda", action="store_true", default=True, help="Enables CUDA training."
)
# è®¾ç½®éšæœºç§å­ã€è®­ç»ƒè½®æ•°ã€å­¦ä¹ ç‡ç­‰è¶…å‚æ•°
parser.add_argument(
    "--fastmode",
    action="store_true",
    default=False,
    help="Validate during training pass.",
)
parser.add_argument("--seed", type=int, default=42, help="Random seed.")
parser.add_argument(
    "--epochs", type=int, default=200, help="Number of epochs to train."
)
parser.add_argument("--lr", type=float, default=0.01, help="Initial learning rate.")
parser.add_argument(
    "--weight_decay",
    type=float,
    default=5e-4,
    help="Weight decay (L2 loss on parameters).",
)
parser.add_argument("--hidden", type=int, default=16, help="Number of hidden units.")
parser.add_argument(
    "--dropout", type=float, default=0.5, help="Dropout rate (1 - keep probability)."
)

args = parser.parse_args()

device = torch.device("cuda" if args.cuda and torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒç»“æœçš„å¯é‡å¤æ€§
np.random.seed(args.seed)
torch.manual_seed(args.seed)
# å¦‚æœä½¿ç”¨ GPUï¼Œè¿˜éœ€è¦ç”¨ torch.cuda.manual_seed() æ¥å›ºå®š GPU çš„éšæœºæ€§
# if args.cuda:
#     torch.cuda.manual_seed(args.seed)
if device.type == "cuda":
    torch.cuda.manual_seed(args.seed)

# step2ï¼šLoad data
adj, features, labels, idx_train, idx_val, idx_test = load_data()

# step3ï¼šModel and optimizer
# psï¼šè®¾ç½®æ¨¡å‹å‚æ•°
model = GCN(
    # å‡å¦‚ features æ˜¯ä¸€ä¸ª (2708, 1433) çš„çŸ©é˜µï¼ˆCora æ•°æ®é›†ï¼‰ï¼Œé‚£ä¹ˆ features.shape[1] å°±æ˜¯ 1433ï¼Œè¡¨ç¤ºæ¯ä¸ªèŠ‚ç‚¹æœ‰ 1433 ä¸ªç‰¹å¾
    nfeat=features.shape[1],  # è¡¨ç¤ºç‰¹å¾çŸ©é˜µçš„åˆ—æ•°ï¼Œå³è¾“å…¥èŠ‚ç‚¹çš„ç‰¹å¾ç»´åº¦
    nhid=args.hidden,  # éšè—å±‚çš„ç¥ç»å…ƒæ•°é‡
    nclass=labels.max().item() + 1,  # åˆ†ç±»æ•°ï¼ˆæ ‡ç­¾çš„æœ€å¤§å€¼ + 1ï¼‰
    dropout=args.dropout,  # Dropout æ¯”ä¾‹
)
# psï¼šè®¾ç½®ä¼˜åŒ–å™¨ï¼Œä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œè®¾ç½®å­¦ä¹ ç‡å’Œæƒé‡è¡°å‡
optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

# å°†æ¨¡å‹å’Œæ•°æ®è¿ç§»åˆ° GPU ä¸Šè¿è¡Œï¼Œä»¥åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹
if args.cuda:
    print("Migrate the model and data to run on the GPU...")
    model = model.to(device)
    features = features.to(device)
    adj = adj.to(device)
    labels = labels.to(device)
    idx_train = idx_train.to(device)
    idx_val = idx_val.to(device)
    idx_test = idx_test.to(device)
    print("Migration is over!")

print(f"Model device: {next(model.parameters()).device}")
print(f"Features device: {features.device}")
print(f"Adjacency matrix device: {adj.device}")
print(f"Labels device: {labels.device}")
print(f"idx_train device: {idx_train.device}")
print(f"idx_val device: {idx_val.device}")
print(f"idx_test device: {idx_test.device}")


# step4ï¼šè®­ç»ƒ
def train(epoch):
    t = time.time()

    # åˆ‡æ¢æ¨¡å‹åˆ°ã€è®­ç»ƒæ¨¡å¼ã€‘
    model.train()
    # æ¸…ç©ºæ¢¯åº¦
    optimizer.zero_grad()
    # 1ã€å‰å‘ä¼ æ’­
    output = model(features, adj)
    # 2ã€è®¡ç®—è®­ç»ƒé›†çš„ã€è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ã€‘
    loss_train = F.nll_loss(output[idx_train], labels[idx_train])
    # 3ã€è®¡ç®—è®­ç»ƒé›†çš„å‡†ç¡®ç‡
    acc_train = accuracy(output[idx_train], labels[idx_train])
    # 4ã€åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
    loss_train.backward()
    # 5ã€æ›´æ–°æ¨¡å‹å‚æ•°
    optimizer.step()

    if not args.fastmode:
        # Evaluate validation set performance separately, deactivates dropout during validation run.
        # åˆ‡æ¢æ¨¡å‹åˆ°ã€éªŒè¯æ¨¡å¼ã€‘
        model.eval()
        # å†æ¬¡è®¡ç®—è¾“å‡ºï¼ˆå…³é—­ Dropoutï¼‰
        output = model(features, adj)

    # 6ã€éªŒè¯æ¨¡å¼ä¸‹é‡æ–°è®¡ç®—è¾“å‡ºï¼Œå¹¶è®°å½•éªŒè¯é›†çš„æŸå¤±å’Œå‡†ç¡®ç‡
    # éªŒè¯é›†æŸå¤±
    loss_val = F.nll_loss(output[idx_val], labels[idx_val])
    # éªŒè¯é›†å‡†ç¡®ç‡
    acc_val = accuracy(output[idx_val], labels[idx_val])
    print(
        "Epoch: {:04d}".format(epoch + 1),
        "loss_train: {:.4f}".format(loss_train.item()),
        "acc_train: {:.4f}".format(acc_train.item()),
        "loss_val: {:.4f}".format(loss_val.item()),
        "acc_val: {:.4f}".format(acc_val.item()),
        "time: {:.4f}s".format(time.time() - t),
    )


# step5ï¼šæµ‹è¯•
def test():
    # åˆ‡æ¢ä¸ºã€è¯„ä¼°æ¨¡å¼ã€‘
    model.eval()
    output = model(features, adj)
    loss_test = F.nll_loss(output[idx_test], labels[idx_test])
    acc_test = accuracy(output[idx_test], labels[idx_test])
    print(
        "Test set results:",
        "loss= {:.4f}".format(loss_test.item()),
        "accuracy= {:.4f}".format(acc_test.item()),
    )


# Train model
t_total = time.time()
for epoch in range(args.epochs):
    train(epoch)

# step6ï¼šæ ¹æ®æ—¶é—´æˆ³ï¼Œä¿å­˜æ¨¡å‹ï¼ˆåœ¨è®­ç»ƒå®Œæˆåä¿å­˜ï¼‰ğŸ‘‡
# ä½¿ç”¨ pytz è·å–å½“å‰æ—¶é—´ï¼Œå¹¶æŒ‡å®šæ—¶åŒº
tz = pytz.timezone("Asia/Shanghai")  # ä¾‹å¦‚ï¼šåŒ—äº¬æ—¶é—´
local_time = datetime.now(tz)
print("Current local time:", local_time.strftime("%Y-%m-%d %H:%M:%S"))
timestamp = local_time.strftime("%Y%m%d-%H%M%S")  # æ ¼å¼åŒ–ä¸ºï¼š20241222-103500
# ä¿å­˜æ¨¡å‹ï¼ˆåŒ…æ‹¬æ¨¡å‹çš„ç»“æ„å’Œå‚æ•°ï¼‰
save_path = f"../checkpoints/model_{timestamp}.pt"
torch.save(model, save_path)
print(f"Model saved to {save_path}")
# æˆ–è€…åªä¿å­˜æ¨¡å‹çš„å‚æ•°ï¼ˆæƒé‡ï¼‰
# torch.save(model.state_dict(), f"gcn_model_epoch_{epoch+1}.pth")

print("Optimization Finished!")
print("Total time elapsed: {:.4f}s".format(time.time() - t_total))

# Testing
test()
